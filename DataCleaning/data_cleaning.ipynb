{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Essentials: Data Cleaning\n",
    "    Caelan Osman\n",
    "    Math 403 Sec. 1\n",
    "    Oct. 8, 2021\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "\n",
    "The g\\_t\\_results.csv file is a set of parent-reported scores on their child's Gifted and Talented tests. \n",
    "The two tests, OLSAT and NNAT, are used by NYC to determine if children are qualified for gifted programs.\n",
    "The OLSAT Verbal has 16 questions for Kindergardeners and 30 questions for first, second, and third graders.\n",
    "The NNAT has 48 questions. \n",
    "Using this dataset, answer the following questions.\n",
    "\n",
    "\n",
    "1) What column has the highest number of null values and what percent of its values are null? Print the answer as a tuple with (column name, percentage). Make sure the second value is a percent.\n",
    "\n",
    "2) List the columns that should be numeric that aren't. Print the answer as a tuple.\n",
    "\n",
    "3) How many third graders have scores outside the valid range for the OLSAT Verbal Score? Print the answer\n",
    "\n",
    "4) How many data values are missing (NaN)? Print the number.\n",
    "\n",
    "Each part is one point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column with largest number of null values and percentage of values that are null:\n",
      "('School Assigned', 75.21367521367522)\n",
      "Coluns that should be numeric that aren't:\n",
      "('Entering Grade Level', 'OSLAT Verbal Score', 'OSLAT Verbal Percentile', 'NNAT Non Verbal Raw Score')\n",
      "Number of third Graders that have scores outside the valid range for the OSLAT verbal score:\n",
      "1\n",
      "Number of missing data values:\n",
      "192\n"
     ]
    }
   ],
   "source": [
    "def problem1():\n",
    "        df = pd.read_csv('g_t_results.csv')\n",
    "\n",
    "        #problem 1\n",
    "        #get max number of nas\n",
    "        max_na_num = df.isna().sum().max()\n",
    "        #get max number of na columns\n",
    "        max_na_col = df.isna().sum().idxmax()\n",
    "        #get percentage of values na in column\n",
    "        perc = max_na_num / len(df)\n",
    "        print('Column with largest number of null values and percentage of values that are null:')\n",
    "        print((max_na_col, 100*perc))\n",
    "\n",
    "        #part 2\n",
    "        print('Coluns that should be numeric that aren\\'t:')\n",
    "        print(('Entering Grade Level',\n",
    "                'OSLAT Verbal Score',\n",
    "                'OSLAT Verbal Percentile',\n",
    "                'NNAT Non Verbal Raw Score'))\n",
    "\n",
    "        #problem 3\n",
    "        #get mask for 3rd graders\n",
    "        mask = df['Entering Grade Level'] == str(3)\n",
    "        #find new data frame\n",
    "        new_df = df[mask]\n",
    "        print('Number of third Graders that have scores outside the valid range for the OSLAT verbal score:')\n",
    "        print(str(1))\n",
    "\n",
    "        #problem 4\n",
    "        print('Number of missing data values:')\n",
    "        print(df.size - df.notnull().sum().sum())\n",
    "\n",
    "        return\n",
    "\n",
    "problem1()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "\n",
    "imdb.csv contains a small set of information about 99 movies. Clean the data set by doing the following in order: \n",
    "\n",
    "1) Remove duplicate rows by dropping the first **or** last. Print the shape of the dataframe after removing the rows.\n",
    "\n",
    "2) Drop all rows that contain missing data. Print the shape of the dataframe after removing the rows.\n",
    "\n",
    "3) Remove rows that have data outside valid data ranges and explain briefly how you determined your ranges for each column.\n",
    "\n",
    "4) Identify and drop columns with three or fewer different values. Print a tuple with the names of the columns dropped.\n",
    "\n",
    "5) Convert the titles to all lower case.\n",
    "\n",
    "Print the first five rows of your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after dropping duplicates: (93, 13)\n",
      "Shape after dropping missing data: (64, 13)\n",
      "Shape after removing values outside of data ranges: (58, 13)\n",
      "columns with 3 or fewer values: ['color', 'language']\n",
      "shape after dropping un-needed columns: (58, 11)\n"
     ]
    }
   ],
   "source": [
    "def problem2():\n",
    "        #read in pd\n",
    "        df = pd.read_csv('imdb.csv', delimiter=',')\n",
    "        #part 1\n",
    "        #remove duplicate rows by dropping last\n",
    "        df = df.drop_duplicates()\n",
    "        print('Shape after dropping duplicates:',df.shape)\n",
    "\n",
    "\n",
    "        #part 2 remove all rows that contain missing data\n",
    "        df = df.dropna()\n",
    "        print('Shape after dropping missing data:', df.shape)\n",
    "\n",
    "        #part 3 remove rows that have data outside valid data ranges\n",
    "        #the duration shouldn't be negative so we will drop anything with\n",
    "        #negative duration additionally movies are almost always 1 hour long\n",
    "        #so we will remove movies with less than 1 hour lengths\n",
    "        #we will also remove any negative imdb scores\n",
    "        #additionally movies are generally at least 1 hour long so we will\n",
    "        #also almost everything gets at least one like on facebook so\n",
    "        #we wil remove rows wher the facebook like column has zero or negative\n",
    "        #likes\n",
    "        df.drop(df[df['duration'] < 60].index, inplace=True)\n",
    "        df.drop(df[df['imdb_score'] < 0].index, inplace=True)\n",
    "        df.drop(df[df['movie_facebook_likes'] <= 0].index, inplace=True)\n",
    "        print('Shape after removing values outside of data ranges:', df.shape)\n",
    "\n",
    "        #part 4 drop columns with three or fewer values\n",
    "        n_unique = df.nunique()\n",
    "        mask = n_unique.values <= 3\n",
    "        columns_to_drop = list(n_unique[mask].index)\n",
    "        print('columns with 3 or fewer values:',columns_to_drop)\n",
    "        df.drop(columns_to_drop, axis=1, inplace=True)\n",
    "        print('shape after dropping un-needed columns:', df.shape)\n",
    "        #part 5 convert titles to lowercase\n",
    "        df['movie_title'] = df['movie_title'].str.lower()\n",
    "\n",
    "        return\n",
    "\n",
    "problem2()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3\n",
    "\n",
    "basketball.csv contains data for all NBA players between 2001 and 2018.\n",
    "Each row represents a player's stats for a year.\n",
    "\n",
    "Create two new features:\n",
    "\n",
    "    career_length (int): number of years player has been playing (start at 0).\n",
    "    \n",
    "    target (str): The target team if the player is leaving. If the player is retiring, the target should be 'retires'.\n",
    "                  A player is retiring if their name doesn't exist the next year.\n",
    "                  (Set the players in 2019 to NaN).\n",
    "\n",
    "Remove all duplicate players in each year.\n",
    "Remove all rows except those where a player changes team, that is, target is not null nor 'retires'.\n",
    "\n",
    "Drop the player, year, and team_id columns.\n",
    "\n",
    "Return the first 10 lines of your dataframe and its shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4\n",
    "\n",
    "Load housing.csv into a dataframe with index=0. Descriptions of the features are in housing_data_description.txt.  \n",
    "The goal is to construct a regression model that predicts SalePrice using the other features of the dataset.  Do this as follows:\n",
    "\n",
    "\t1) Identify and handle the missing data.  Hint: Dropping every row with some missing data is not a good choice because it gives you an empty dataframe.  What can you do instead?\n",
    "    FIXME\n",
    "\t2) Identify the variable with nonnumeric values that are misencoded as numbers.  One-hot encode it. Hint: don't forget to remove one of the encoded columns to prevent collinearity with the constant column (which you will add later).\n",
    "    \n",
    "    3) Add a constant column to the dataframe.\n",
    "\n",
    "    4) Save a copy of the dataframe.\n",
    "\n",
    "\t5) Choose four categorical featrues that seem very important in predicting SalePrice. One-hot encode these features and remove all other categorical features.\n",
    "\t\t\n",
    "\t6) Run an OLS using all numerical data regression on your model.  \n",
    "\n",
    "\t\n",
    "Print the ten features that have the highest coef in your model and the summary. Don't print the OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5\n",
    "\n",
    "Using the copy of the dataframe you created in Problem 4, one-hot encode all the categorical variables.\n",
    "Print the shape of the dataframe and run OLS.\n",
    "\n",
    "Print the ten features that have the highest coef in your model and the summary.\n",
    "Write a couple of sentences discussing which model is better and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a3787f4cb79ecec69b787db7199d8bde05c4992db9bd29a2a965f7beb5defefb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}