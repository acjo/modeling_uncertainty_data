{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from imageio import imread\n",
    "from sklearn import datasets\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![6.10](6_10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![6.11.12](6_11_12.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Exercise 6.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadratic Discriminant Analysis:\n",
      "Training/Test time: 0.0023360252380371094\n",
      "Score: 0.9649122807017544\n",
      "\n",
      "Logistic Regression:\n",
      "Training/Test time: 0.00690007209777832\n",
      "Score: 0.9473684210526315\n",
      "\n",
      "Gaussian Naive Bayes:\n",
      "Training/Test time: 0.001813650131225586\n",
      "Score: 0.9181286549707602\n"
     ]
    }
   ],
   "source": [
    "def prob6_13():\n",
    "    #load in dataset and get train, test, split\n",
    "    BC = datasets.load_breast_cancer()\n",
    "    X = BC.data\n",
    "    y = BC.target\n",
    "    X_train, X_test, y_train, y_test =\\\n",
    "        train_test_split(X, y, train_size=0.7)\n",
    "\n",
    "    #train QDA\n",
    "    start = time.time()\n",
    "    QDA = QuadraticDiscriminantAnalysis()\n",
    "    QDA.fit(X_train, y_train)\n",
    "    QDA_score = QDA.score(X_test, y_test)\n",
    "    end = time.time()\n",
    "\n",
    "    print('Quadratic Discriminant Analysis:')\n",
    "    print('Training/Test time:', end-start)\n",
    "    print('Score:', QDA_score )\n",
    "\n",
    "    #train Logistic Regression\n",
    "    start = time.time()\n",
    "    LR = LogisticRegression(solver='liblinear')\n",
    "    LR.fit(X_train, y_train)\n",
    "    LR_score = LR.score(X_test, y_test)\n",
    "    end = time.time()\n",
    "    print()\n",
    "    print('Logistic Regression:')\n",
    "    print('Training/Test time:', end-start)\n",
    "    print('Score:', LR_score )\n",
    "\n",
    "    #train Naive Bayes\n",
    "    start = time.time()\n",
    "    GNB = GaussianNB()\n",
    "    GNB.fit(X_train, y_train)\n",
    "    GNB_score = GNB.score(X_test, y_test)\n",
    "    end = time.time()\n",
    "    print()\n",
    "    print('Gaussian Naive Bayes:')\n",
    "    print('Training/Test time:', end-start)\n",
    "    print('Score:', GNB_score )\n",
    "    return\n",
    "\n",
    "prob6_13()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how close QDA and the logistic regression are, this is because of the theorem we proved in the homework. That QDA boils down to a softmax regression problem. But also notice that QDA and Naive Bayes are much quicker to train and test as we would expect from the discussion in the book. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
