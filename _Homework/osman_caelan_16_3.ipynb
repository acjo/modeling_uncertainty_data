{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> Homework 16.3 </h1>\n",
    "<h1 align=\"center\">Caelan Osman </h1>\n",
    "<h1 align=\"center\">March 8, 2022 </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets.fashion_mnist import load_data\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 16.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N:  3 ,eps:  0.7\n",
      "Number of failures before passing:  0\n",
      "\n",
      "N:  3 ,eps:  0.5\n",
      "Number of failures before passing:  0\n",
      "\n",
      "N:  3 ,eps:  0.1\n",
      "Number of failures before passing:  0\n",
      "\n",
      "N:  10 ,eps:  0.7\n",
      "Number of failures before passing:  0\n",
      "\n",
      "N:  10 ,eps:  0.5\n",
      "Number of failures before passing:  0\n",
      "\n",
      "N:  10 ,eps:  0.1\n",
      "Number of failures before passing:  1\n",
      "\n",
      "N:  100 ,eps:  0.7\n",
      "Number of failures before passing:  0\n",
      "\n",
      "N:  100 ,eps:  0.5\n",
      "Number of failures before passing:  0\n",
      "\n",
      "N:  100 ,eps:  0.1\n",
      "Number of failures before passing:  0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def JL_Bound(N, eps):\n",
    "    \"\"\"\n",
    "    Computes the Johnson-Lindenstrauss bound k\n",
    "\n",
    "    parameters:\n",
    "        n (int): number of points\n",
    "        eps (float): maximal allowed distortion of the distance\n",
    "    \n",
    "    Returns:\n",
    "        k (int): the dimensional bound\n",
    "    \"\"\"\n",
    "\n",
    "    return int(np.ceil(24*np.log(N)/(3*eps**2 - 2*eps**3)))\n",
    "\n",
    "def preserves_distance(X, A, eps, ord=2):\n",
    "    \"\"\"\n",
    "    This checks if a linear transformation preserves distance between points\n",
    "    up to some distortion epsilon. \n",
    "\n",
    "    Parameters:\n",
    "        X: np.ndarray ((N, d)) N is the number of points d is the dimension\n",
    "        A: np.ndarray ((k, d)) A: R^d - R^k\n",
    "        eps: (float) distortion constatnd\n",
    "        ord: (int) order of norm\n",
    "\n",
    "    Returns:\n",
    "        boolean: if the linear transformation preserves distance\n",
    "    \"\"\"\n",
    "\n",
    "    preserves = True\n",
    "    N, _ = X.shape\n",
    "    for i in range(N):\n",
    "        for j in range(i+1, N):\n",
    "\n",
    "            # check preservation\n",
    "            lower_bound = (1 - eps)*np.linalg.norm(X[i] - X[j], ord=ord)**2 <= np.linalg.norm(A@X[i] -A@X[j], ord=ord)**2\n",
    "            upper_bound = (1 + eps)*np.linalg.norm(X[i] - X[j], ord=ord)**2 >= np.linalg.norm(A@X[i] -A@X[j], ord=ord)**2\n",
    "            preserves = lower_bound and upper_bound\n",
    "\n",
    "            if not preserves:\n",
    "                return False\n",
    "\n",
    "    return True\n",
    "\n",
    "def random_points(N, d=10**5):\n",
    "    \"\"\"\n",
    "    Uniformly draws N random points from R^d\n",
    "    \"\"\"\n",
    "    return np.random.uniform(low=-10000, high=10000, size=(N, d))\n",
    "\n",
    "def random_projection(k, d=10**5):\n",
    "    \"\"\" \n",
    "    Constructs a random projection where each entries is drawn from\n",
    "    N(0, 1/k)\n",
    "    \"\"\"\n",
    "    return np.random.normal(loc=0, scale=np.sqrt(1/k), size=(k, d))\n",
    "\n",
    "def run_projection_test():\n",
    "    \"\"\"\n",
    "    Tests if a random projection preserves distance for a random points\n",
    "    \"\"\"\n",
    "\n",
    "    N_vals = [3, 10, 100]\n",
    "    Eps = [0.7, 0.5, 0.1]\n",
    "\n",
    "    Failures_before_pass = {(N, eps) : -1 for N in N_vals for eps in Eps}\n",
    "\n",
    "    for N in N_vals:\n",
    "        X =  random_points(N)\n",
    "        for eps in Eps:\n",
    "            passed = False\n",
    "            k = JL_Bound(N, eps)\n",
    "            while not passed:\n",
    "                A = random_projection(k)\n",
    "                passed = preserves_distance(X, A, eps)\n",
    "\n",
    "                Failures_before_pass[(N, eps)] += 1\n",
    "\n",
    "    return Failures_before_pass\n",
    "\n",
    "FBP = run_projection_test()\n",
    "\n",
    "for key in list(FBP.keys()):\n",
    "    print(\"N: \", key[0], \",eps: \", key[1])\n",
    "    print('Number of failures before passing: ', FBP[key])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see only one combination $N = 10$ and $\\varepsilon = 0.1$ failed before passing. Every other combination passed first try. \n",
    "\n",
    "\n",
    "## Exercise 16.14\n",
    "\n",
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_projection_mnist():\n",
    "\n",
    "    # load data\n",
    "    (x_train, y_train), (x_test, y_test) = load_data()\n",
    "    # convert to 728 flattened images\n",
    "    input_dim = 784 #28*28\n",
    "    X_train = x_train.reshape(60000, input_dim)\n",
    "    X_test = x_test.reshape(10000, input_dim)\n",
    "\n",
    "    # scale images\n",
    "    X_train = X_train/255\n",
    "    X_test = X_test/255\n",
    "\n",
    "    # randomly pick which features to keep\n",
    "    keep_features = np.random.choice(np.arange(0, input_dim), size=int(input_dim/10), replace=False)\n",
    "    X_train = X_train[:, keep_features]\n",
    "    X_test = X_test[:, keep_features]\n",
    "\n",
    "    # we now change the sign on half of them\n",
    "    change_sign = np.random.choice(np.arange(0, X_train.shape[1]), size = int(X_train.shape[1]/2), replace=False)\n",
    "    X_train[:, change_sign] *= -1\n",
    "    X_test[:, change_sign] *= -1\n",
    "\n",
    "    return X_train, X_test\n",
    "\n",
    "def unmodified_data():\n",
    "    # load data\n",
    "    (x_train, y_train), (x_test, y_test) = load_data()\n",
    "    # convert to 728 flattened images\n",
    "    input_dim = 784 #28*28\n",
    "    X_train = x_train.reshape(60000, input_dim)\n",
    "    X_test = x_test.reshape(10000, input_dim)\n",
    "\n",
    "    # scale images\n",
    "    X_train = X_train/255\n",
    "    X_test = X_test/255\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train GBT on original data:  338.0774824619293\n",
      "Time to train GBT on randomly projected data:  34.56087255477905\n"
     ]
    }
   ],
   "source": [
    "def train_gradient_boosted():\n",
    "    # get data\n",
    "    X_train, y_train, _, _ = unmodified_data()\n",
    "    X_train_projection, _ = random_projection_mnist()\n",
    "    N = X_train.shape[0]\n",
    "    training_set = np.random.choice(np.arange(0, N), size = int(N/10),  replace=False) \n",
    "\n",
    "    # time GBT on original data\n",
    "    start = time.time()\n",
    "    clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,  max_depth=1, random_state=0).fit(X_train[training_set], y_train[training_set])\n",
    "    end = time.time()\n",
    "    unmodified_time = end - start\n",
    "\n",
    "    # time GBT on modified data\n",
    "    start = time.time()\n",
    "    clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,  max_depth=1, random_state=0).fit(X_train_projection[training_set], y_train[training_set])\n",
    "    end = time.time()\n",
    "    modified_time = end - start\n",
    "\n",
    "    return unmodified_time, modified_time\n",
    "\n",
    "unmodified_time, modified_time = train_gradient_boosted()\n",
    "\n",
    "print('Time to train GBT on original data: ', unmodified_time)\n",
    "print('Time to train GBT on randomly projected data: ', modified_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBT score on original data:  0.6616\n",
      "GBT score on randomly projected data:  0.7612\n"
     ]
    }
   ],
   "source": [
    "def score_gradient_boosted():\n",
    "    # get and modify data\n",
    "\n",
    "    X_train, y_train, X_test, y_test = unmodified_data()\n",
    "    X_train_projection, X_test_projection = random_projection_mnist()\n",
    "    N = X_train.shape[0]\n",
    "    training_set = np.random.choice(np.arange(0, N), size = int(N/10), replace=False) \n",
    "\n",
    "    # train and score GBT on original data\n",
    "    clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,  max_depth=1, random_state=0).fit(X_train[training_set], y_train[training_set])\n",
    "    unmodified_score = clf.score(X_test, y_test)\n",
    "\n",
    "    # train and score GBT on modified data\n",
    "    clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,  max_depth=1, random_state=0).fit(X_train_projection[training_set], y_train[training_set])\n",
    "    modified_score = clf.score(X_test_projection, y_test)\n",
    "\n",
    "    return unmodified_score, modified_score\n",
    "\n",
    "unmodified_score, modified_score = score_gradient_boosted()\n",
    "\n",
    "print('GBT score on original data: ', unmodified_score)\n",
    "print('GBT score on randomly projected data: ', modified_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to compute SVD on original data:  8.219223737716675\n"
     ]
    }
   ],
   "source": [
    "def time_PCA():\n",
    "    # get and modify data\n",
    "    X_train, y_train, X_test, y_test = unmodified_data()\n",
    "\n",
    "    N = X_train.shape[0]\n",
    "    training_set = np.random.choice(np.arange(0, N), size = int(N/10),  replace=False) \n",
    "    X_train = X_train[training_set]\n",
    "\n",
    "    # compute and time PCA on original data\n",
    "    start = time.time()\n",
    "    _, _, VH = np.linalg.svd(X_train)\n",
    "    X_train @ VH[:20, :].T\n",
    "    _, _, VH = np.linalg.svd(X_test)\n",
    "    X_test @ VH[:20, :].T\n",
    "    end = time.time()\n",
    "    PCA_time = end - start\n",
    "\n",
    "\n",
    "    return PCA_time\n",
    "\n",
    "\n",
    "print('Time to compute SVD on original data: ', time_PCA())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5 and 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to compute SVD and train GBT on original data:  24.586934804916382\n",
      "Score:  0.1234\n",
      "Time to train GBT on projected data:  18.622740745544434\n",
      "Score:  0.6541\n"
     ]
    }
   ],
   "source": [
    "def PCA_GBT_accuracy_time():\n",
    "\n",
    "    # set up training data\n",
    "    X_train, y_train, X_test, y_test = unmodified_data()\n",
    "    X_train_projection, X_test_projection = random_projection_mnist()\n",
    "\n",
    "    N = X_train.shape[0]\n",
    "    training_set = np.random.choice(np.arange(0, N), size = int(N/10),  replace=False) \n",
    "\n",
    "    X_train = X_train[training_set]\n",
    "    X_train_projection = X_train_projection[training_set]\n",
    "\n",
    "    start = time.time()\n",
    "    # compute PCA\n",
    "    _, _, VH = np.linalg.svd(X_train)\n",
    "    PCA_train = X_train @ VH[:20, :].T\n",
    "    _, _, VH = np.linalg.svd(X_test)\n",
    "    PCA_test = X_test @ VH[:20, :].T\n",
    "    # train tree\n",
    "    clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,  max_depth=1, random_state=0).fit(PCA_train, y_train[training_set])\n",
    "    end = time.time()\n",
    "    # time and score unmodified data\n",
    "    unmodified_time = end - start\n",
    "    _, _, VH = np.linalg.svd(X_test)\n",
    "    unmodified_score = clf.score(PCA_test, y_test)\n",
    "\n",
    "    start = time.time()\n",
    "    # train tree\n",
    "    clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,  max_depth=1, random_state=0).fit(X_train_projection, y_train[training_set])\n",
    "    end = time.time()\n",
    "    # time and score modified data\n",
    "    modified_time = end - start\n",
    "    modified_score = clf.score(X_test_projection, y_test)\n",
    "\n",
    "    return unmodified_time, unmodified_score, modified_time, modified_score\n",
    "\n",
    "unmodified_time, unmodified_score, modified_time, modified_score = PCA_GBT_accuracy_time()\n",
    "\n",
    "print('Time to compute SVD and train GBT on original data: ', unmodified_time)\n",
    "print('Score: ', unmodified_score)\n",
    "\n",
    "print('Time to train GBT on projected data: ', modified_time)\n",
    "print('Score: ', modified_score)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a3787f4cb79ecec69b787db7199d8bde05c4992db9bd29a2a965f7beb5defefb"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}