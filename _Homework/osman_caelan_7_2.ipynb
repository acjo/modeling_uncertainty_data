{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import product\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tensorflow import keras\n",
    "from sklearn import datasets\n",
    "from tensorflow.keras import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Exercise 7.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1:\n",
      "0.726775956284153\n",
      "\n",
      "part 2: \n",
      "best oob score\n",
      "0.7923497267759563\n",
      "best hyper-parameters\n",
      "{'max_depth': 38, 'max_features': 6}\n",
      "\n",
      "Part 3:\n",
      "most important features: Index(['Age', 'Fare', 'Sex_male'], dtype='object')\n",
      "least important features: Index(['Embarked_Q', 'Pclass_3', 'Pclass_2'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def problem7_5():\n",
    "    #part 1\n",
    "    RFC = RandomForestClassifier(bootstrap=True, oob_score=True, warm_start=False)\n",
    "\n",
    "    titanic = pd.read_csv('train.csv')\n",
    "    titanic.dropna(inplace=True)\n",
    "    X = titanic.drop(['Cabin', 'Name', 'PassengerId', 'Ticket'], axis=1)\n",
    "    X = pd.get_dummies(X, columns=['Pclass', 'Sex', 'Embarked'], drop_first=True)\n",
    "    X = X.dropna()\n",
    "    y = X['Survived']\n",
    "    X = X.drop(['Survived'], axis=1)\n",
    "    print('Part 1:', RFC.fit(X, y).oob_score_, sep='\\n')\n",
    "\n",
    "    #part 2 find the best hyperparameters max_depth and max_features\n",
    "    max_features_params = ['auto', 'sqrt', 'log2']\n",
    "    max_depth_params = list(np.arange(35, 60))\n",
    "    max_features_params += list(np.arange(1, 10))\n",
    "    #get all possible combinations\n",
    "    combinations = list(product(max_depth_params, max_features_params))\n",
    "    best_oob_score = -np.inf\n",
    "    #iterate through and get best score\n",
    "    for max_d, max_f in combinations:\n",
    "        RFC = RandomForestClassifier(max_depth=max_d,\n",
    "                                     max_features=max_f,\n",
    "                                     bootstrap=True,\n",
    "                                     oob_score=True,\n",
    "                                     warm_start=False)\n",
    "        curr_oob_score = RFC.fit(X, y).oob_score_\n",
    "        if curr_oob_score > best_oob_score:\n",
    "            best_oob_score = curr_oob_score\n",
    "            best_params = {'max_depth' : max_d, 'max_features' : max_f}\n",
    "\n",
    "    print()\n",
    "    print('part 2: ')\n",
    "    print('best oob score', best_oob_score, sep='\\n')\n",
    "    print('best hyper-parameters', best_params, sep='\\n')\n",
    "\n",
    "    #part 3 build the most optimal random forest classifier\n",
    "    RFC = RandomForestClassifier(max_depth = best_params['max_depth'],\n",
    "                                 max_features=best_params['max_features'],\n",
    "                                 bootstrap=True,\n",
    "                                 oob_score=True,\n",
    "                                 warm_start=True)\n",
    "\n",
    "    #get most important features\n",
    "    RFC.fit(X, y)\n",
    "    impurities = RFC.feature_importances_\n",
    "    #sort indexes by highest to lowest\n",
    "    min_indexes = np.argsort(impurities)\n",
    "    max_indexes = np.argsort(impurities)[::-1]\n",
    "\n",
    "    print()\n",
    "    print('Part 3:')\n",
    "    print('most important features:', X.columns[max_indexes[:3]] )\n",
    "    print('least important features:', X.columns[min_indexes[:3]] )\n",
    "\n",
    "    return\n",
    "\n",
    "problem7_5()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Exercise 7.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best oob score:\n",
      "0.8754333333333333\n",
      "Best hyper parameters: \n",
      "{'max_features': 9, 'max_depth': 23}\n"
     ]
    }
   ],
   "source": [
    "def problem7_6():\n",
    "    #compltes problem 7.6\n",
    "    (X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "\n",
    "    input_dim = 784 #28*28\n",
    "    X_train = X_train.reshape(60000, input_dim)\n",
    "    X_test = X_test.reshape(10000, input_dim)\n",
    "    X_train = X_train/255\n",
    "    X_test = X_test/255\n",
    "    y_train = utils.to_categorical(y_train, 10)\n",
    "    y_test = utils.to_categorical(y_test, 10)\n",
    "\n",
    "    feature_list = list(np.arange(5, 10))\n",
    "    depth_list = list(np.arange(20, 25))\n",
    "    combinations = list(product(feature_list, depth_list))\n",
    "\n",
    "    best_oob_score = -np.inf\n",
    "    for feat, dep in combinations:\n",
    "        RFC = RandomForestClassifier(n_estimators= 200,\n",
    "                                     max_features=feat,\n",
    "                                     max_depth=dep,\n",
    "                                     bootstrap=True,\n",
    "                                     oob_score=True,\n",
    "                                     warm_start=True)\n",
    "        RFC.fit(X_train, y_train)\n",
    "        curr_score = RFC.oob_score_\n",
    "        if curr_score > best_oob_score:\n",
    "            best_oob_score = curr_score\n",
    "            best_hyper_params = {'max_features':feat, 'max_depth': dep}\n",
    "\n",
    "    print('Best oob score:', best_oob_score, sep='\\n' )\n",
    "    print('Best hyper parameters: ', best_hyper_params, sep='\\n')\n",
    "\n",
    "    return\n",
    "\n",
    "problem7_6()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Exercise 7.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part 1: \n",
      "best oob score\n",
      "0.8925588434244296\n",
      "best hyper-parameters\n",
      "{'max_depth': 35, 'max_features': 4}\n",
      "\n",
      "Part 2:\n",
      "most important features: Index(['RM', 'LSTAT', 'INDUS'], dtype='object')\n",
      "least important features: Index(['ZN', 'CHAS', 'RAD'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def problem7_7():\n",
    "    boston = datasets.load_boston()\n",
    "    X = boston.data\n",
    "\n",
    "    y = boston.target\n",
    "\n",
    "    features = [\"CRIM\", \"ZN\", \"INDUS\", \"CHAS\", \"NOX\", \"RM\", \"AGE\", \"DIS\",\n",
    "                \"RAD\", \"TAX\", \"PTRATIO\", \"B\", \"LSTAT\"]\n",
    "\n",
    "    X = pd.DataFrame(X, columns=features)\n",
    "\n",
    "\n",
    "\n",
    "    max_features_params = ['auto', 'sqrt', 'log2']\n",
    "    max_depth_params = list(np.arange(35, 60))\n",
    "    max_features_params += list(np.arange(1, 10))\n",
    "    #get all possible combinations\n",
    "    combinations = list(product(max_depth_params, max_features_params))\n",
    "    best_oob_score = -np.inf\n",
    "    #iterate through and get best score\n",
    "    for max_d, max_f in combinations:\n",
    "        RFR = RandomForestRegressor(max_depth=max_d,\n",
    "                                     max_features=max_f,\n",
    "                                     bootstrap=True,\n",
    "                                     oob_score=True,\n",
    "                                     warm_start=False)\n",
    "        curr_oob_score = RFR.fit(X, y).oob_score_\n",
    "        if curr_oob_score > best_oob_score:\n",
    "            best_oob_score = curr_oob_score\n",
    "            best_params = {'max_depth' : max_d, 'max_features' : max_f}\n",
    "\n",
    "    print('part 1: ')\n",
    "    print('best oob score', best_oob_score, sep='\\n')\n",
    "    print('best hyper-parameters', best_params, sep='\\n')\n",
    "\n",
    "    #part 3 build the most optimal random forest classifier\n",
    "    RFR = RandomForestRegressor(max_depth = best_params['max_depth'],\n",
    "                                 max_features=best_params['max_features'],\n",
    "                                 bootstrap=True,\n",
    "                                 oob_score=True,\n",
    "                                 warm_start=True)\n",
    "\n",
    "    #get most important features\n",
    "    RFR.fit(X, y)\n",
    "    impurities = RFR.feature_importances_\n",
    "    #sort indexes by highest to lowest\n",
    "    min_indexes = np.argsort(impurities)\n",
    "    max_indexes = np.argsort(impurities)[::-1]\n",
    "\n",
    "    print()\n",
    "    print('Part 2:')\n",
    "    print('most important features:', X.columns[max_indexes[:3]] )\n",
    "    print('least important features:', X.columns[min_indexes[:3]] )\n",
    "\n",
    "    return\n",
    "\n",
    "problem7_7()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Exercise 7.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part 1:\n",
      "Best oob scare\n",
      "0.017423771001866834\n",
      "Best hyperparameters:\n",
      "{'n_estimators': 7, 'max_depth': 31, 'max_features': 1}\n",
      "\n",
      "part 2:\n",
      "Accuracy of Random Forest Classifier\n",
      "0.013130615065653075\n",
      "Accuracy of Logistic Regression\n",
      "0.013821700069108501\n",
      "Accuracy of Linear Regression\n",
      "0.02568467899269289\n",
      "\n",
      "Part 3:\n",
      "most important features: Index(['DayOfWeek', 'Scheduled_Arrival', 'Scheduled_Departure'], dtype='object')\n",
      "least important features: Index(['Origin_Airport_DTW', 'Origin_Airport_EWR', 'Origin_Airport_CLT'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def problem7_8():\n",
    "    #part 1\n",
    "\n",
    "    def data_cleaning():\n",
    "        '''This function cleans the data we will be using\n",
    "        :return:\n",
    "        flight_2016: pandas dataframe with the cleaned flight data from 2016\n",
    "        flight_2017: pandas dataframe with the cleaned fligth data from 2017\n",
    "        '''\n",
    "        flight_2016 = pd.read_csv('flight.csv', delimiter=',')\n",
    "        #drop useless flight data\n",
    "        flight_2016.drop(['Month', 'Year', 'Day', 'Flight_Date', 'FlightNum',\n",
    "                      'Departure_Time','Dep_Delay', 'DepDel15', 'Dep_Delay_Groups',\n",
    "                      'Arrival_Time', 'Arr_Delay_Minutes',\n",
    "                      'Arr_Del_morethan15', 'Cancelled', 'Diverted',\n",
    "                      'DistanceGroup', 'UniqueCarrier', 'Carrier_Delay', 'WeatherDelay', 'NAS_Delay',\n",
    "                      'Security_Delay', 'Late_Aircraft_Delay', 'Top_Carriers', 'Top_Origin',\n",
    "                      'DEPTIME_GROUP1', 'DEPTIME_GROUP2', 'DEPTIME_GROUP3' , 'Tai_lNum', 'Origin_City_Name', 'Origin_State'], axis=1, inplace=True)\n",
    "\n",
    "        #change to be rolling departure times\n",
    "        mask = flight_2016['Scheduled_Departure'] >= 1200\n",
    "        flight_2016[mask]['Scheduled_Departure'] *= -1\n",
    "        flight_2016[mask]['Scheduled_Departure'] += 2400\n",
    "\n",
    "        flight_2017 = pd.read_csv('fl_samp.csv', delimiter=',')\n",
    "        #drop useless flight data\n",
    "        flight_2017.drop(['Year', 'Month', 'Day', 'Flight_Date', 'UniqueCarrier', 'Departure_Time',\n",
    "                      'Scheduled_Arrival', 'Dep_Delay', 'Arr_Del_morethan15', 'DistanceGroup',\n",
    "                      'Carrier_Delay', 'WeatherDelay', 'NAS_Delay', 'Late_Aircraft_Delay',\n",
    "                      'DEPTIME_GROUP1', 'DEPTIME_GROUP2', 'DEPTIME_GROUP3' ], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "        return flight_2016, flight_2017\n",
    "\n",
    "    flight_2016, _ = data_cleaning()\n",
    "    flight_2016 = pd.get_dummies(flight_2016, columns=['Origin_Airport'], drop_first=True)\n",
    "\n",
    "    y = flight_2016['Arrival_Delay']\n",
    "    X = flight_2016.drop(['Arrival_Delay'], axis=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                        y,\n",
    "                                                        train_size=0.7,\n",
    "                                                        random_state=0)\n",
    "\n",
    "    estimator = list(np.arange(1, 10))\n",
    "    depth = list(np.arange( 30, 45))\n",
    "    features = list(np.arange(1, 6))\n",
    "\n",
    "    combinations = list(product(estimator, depth, features))\n",
    "    best_oob_score = -np.inf\n",
    "    for est, dep, feat in combinations:\n",
    "        RFR = RandomForestClassifier( n_estimators=est,\n",
    "                                    max_depth=dep,\n",
    "                                    max_features=feat,\n",
    "                                    bootstrap=True,\n",
    "                                    oob_score=True,\n",
    "                                    warm_start=False)\n",
    "\n",
    "        curr_oob_score = RFR.fit(X, y).oob_score_\n",
    "        if curr_oob_score > best_oob_score:\n",
    "            best_oob_score = curr_oob_score\n",
    "            best_params = {'n_estimators': est, 'max_depth' : dep, 'max_features' : feat}\n",
    "\n",
    "    print('part 1:')\n",
    "    print('Best oob scare', best_oob_score, sep='\\n')\n",
    "    print('Best hyperparameters:', best_params, sep='\\n')\n",
    "\n",
    "    RFC = RandomForestClassifier( n_estimators=best_params['n_estimators'],\n",
    "                                  max_depth = best_params['max_depth'],\n",
    "                                  max_features = best_params['max_features'],\n",
    "                                  bootstrap=True,\n",
    "                                  oob_score=True,\n",
    "                                  warm_start=False\n",
    "                                  )\n",
    "    RFC.fit(X_train, y_train)\n",
    "    LinR = LinearRegression()\n",
    "    LinR.fit(X_train, y_train)\n",
    "    LR = LogisticRegression()\n",
    "    LR.fit(X_train, y_train)\n",
    "\n",
    "    print()\n",
    "    print('part 2:')\n",
    "    print('Accuracy of Random Forest Classifier', RFC.score(X_test, y_test), sep='\\n')\n",
    "    print('Accuracy of Logistic Regression', LR.score(X_test, y_test), sep='\\n')\n",
    "    print('Accuracy of Linear Regression', LinR.score(X_test, y_test), sep='\\n')\n",
    "\n",
    "    impurities = RFC.feature_importances_\n",
    "    #sort indexes by highest to lowest\n",
    "    min_indexes = np.argsort(impurities)\n",
    "    max_indexes = np.argsort(impurities)[::-1]\n",
    "\n",
    "    print()\n",
    "    print('Part 3:')\n",
    "    print('most important features:', X.columns[max_indexes[:3]] )\n",
    "    print('least important features:', X.columns[min_indexes[:3]] )\n",
    "\n",
    "    return\n",
    "\n",
    "problem7_8()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}